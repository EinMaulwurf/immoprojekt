---
title: "auswertung.Rmd"
output: github_document
date: "2023-12-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 5, fig.height = 3)
```

# Libraries
```{r message=FALSE}
# Für Korrelationsmatrizen
library(Hmisc)

# Für Übersichts-Plots
#library(GGally)

# Für schönere Latex-Tabellen
library(stargazer)
library(kableExtra)
library(vtable)

# Für heteroscedasticity-consistent tests
library(sandwich)
library(lmtest)

# Für schönere Plots
library(ggpubr)
library(ggrepel)

# Für schnelleres Einlesen von Daten
library(vroom)

# Für allgemeine Datenmanipulation und Plotten
library(tidyverse)

# Für tidy Regressionsergebnisse
library(broom)

# Fürs Arbeiten mit Geodaten
library(sf)
```

# Importieren der Daten
Die Daten wurden im Dokument 'cleaning.Rmd' aufbereitet und abgespeichert.
```{r, message=FALSE}
data_rent <- vroom("./daten/data_rent.csv")
data_social <- vroom("./daten/data_social.csv")

inspire_grid_berlin <- st_read("./daten/inspire_grid_berlin.gpkg")
bezirksgrenzen_berlin <- st_read("./daten/bezirksgrenzen_berlin/bezirksgrenzen.shp") %>%
  st_transform("EPSG:3035")
```

# Summary Statistics

**TODO**

Überblick über die beiden Datensätze mit Anzahl an Beobachtungen, Mittelwert, Median, Quartilen und mehr.
```{r}
data_social %>% select(-jahr, -r1_id) %>%
  pivot_longer(cols = everything()) %>%
  group_by(name) %>%
  drop_na() %>%
  summarise(n = n(), 
            mean = mean(value),
            Std.Dev. = sd(value),
            min = min(value),
            Pctl.25 = quantile(value, probs = 0.25),
            Pctl.50 = quantile(value, probs = 0.5),
            Pctl.75 = quantile(value, probs = 0.75),
            max = max(value))

data_rent %>% select(-jahr, -r1_id) %>%
  pivot_longer(cols = everything()) %>%
  group_by(name) %>%
  drop_na() %>%
  summarise(n = n(), 
            mean = mean(value),
            Std.Dev. = sd(value),
            min = min(value),
            Pctl.25 = quantile(value, probs = 0.25),
            Pctl.50 = quantile(value, probs = 0.5),
            Pctl.75 = quantile(value, probs = 0.75),
            max = max(value))
```

Korrelation zwischen Variablen
```{r}
mcor_social <- data_social %>%
  select_if(is.numeric) %>%
  select(-jahr) %>%
  as.matrix() %>%
  Hmisc::rcorr() %>%
  .$r
mcor_social[upper.tri(mcor_social)] <- NA

mcor_social %>%
  data.frame() %>%
  round(2)
# Hinzufügen, um Latex Tabelle zu erhalten
#  %>%
#  kbl(
#    format = "latex",
#    digits = 2,
#    booktabs = T,
#    toprule = "\\hline \\hline",
#    midrule = "\\hline",
#    bottomrule = "\\hline \\hline",
#    linesep = "",
#  ) %>%
#  cat()

mcor_social %>%
  data.frame() %>%
  round(2) %>%
  rownames_to_column() %>%
  pivot_longer(cols = -rowname) %>%
  filter(!is.na(value), value != 1) %>%
  arrange(desc(value)) %>%
  rename(variable1 = rowname, variable2 = name, korrelation = value)
```

Die größte Korrelation liegt zwischen dem Anteil an Wohnblocks und der Anzahl der Haushalte vor. Das ist soweit nicht überraschend. Als nächstes folgt mit einem Korrelationskoeffizienten von 0.7 der Zusammenhang zwischen dem Kreditrisiko und dem Anteil an Wohnblocks.

# Plotting
## Berlin Karte
Der INSPIRE Grid mit den Berliner Bezirken
```{r}
ggplot()+
  geom_sf(data = inspire_grid_berlin)+
  geom_sf(data = bezirksgrenzen_berlin, fill = "white", alpha = .8, color = "black")+
  ggrepel::geom_label_repel(data = bezirksgrenzen_berlin %>% mutate(Gemeinde_n = str_replace(Gemeinde_n, "-", "-\n")), 
                           aes(label = Gemeinde_n, geometry = geometry),
                           stat = "sf_coordinates",
                           min.segment.length = 0.2, 
                           force_pull = 50,
                           box.padding = 0.1,
                           label.padding = .1,
                           size = 2,
                           label.r = 0,
                           lineheight = 1,
                           fill = "white")+
  coord_sf(crs = 3035)+
  #geom_sf_text(data = bezirksgrenzen_berlin %>% mutate(Gemeinde_n = str_replace(Gemeinde_n, "-", "-\n")), aes(label = Gemeinde_n), size = 3)+
  theme_bw()

ggsave("./plots/plot_berlin_karte.pdf")
```

Der hier gezeigt Teil des Grids hat 1016 Quadrate, also eine Fläche von 1016km². Berlin hat genaugenommen nur eine Fläche von 891,8 km², wir betrachten also auch teilweise Flächen, die eigentlich nicht mehr zu Berlin gehören, da wir alle Quadrate einbeziehen, die (auch nur teilweise) mit den Stadtgrenzen überlappen. Die andere Möglichkeit wäre gewesen, die Fläche zu unterschätzen und nur Quadrate zu betrachten, die komplett innerhalb der Stadtgrenzen liegen.

## Rent Daten
Wie hat sich die Verteilung der Kaltmieten über die Jahre geändert?
```{r, fig.width=7.5, fig.height=4.5}
plot1 <- data_rent %>%
  filter(jahr %in% 2010:2020) %>%
  mutate(mietekalt_m2 = mietekalt / wohnflaeche) %>%
  filter(mietekalt_m2 > 0, mietekalt_m2 < 100) %>%
  ggplot(aes(x = jahr, y = mietekalt_m2, group = jahr))+
  geom_boxplot(outlier.shape = NA)+
  coord_cartesian(ylim = c(0, 30))+
  scale_x_continuous(breaks = 2010:2020, labels = 10:20)+
  theme_bw()+
  labs(x = "Jahr", y = "Kaltmiete pro m²")

plot2 <- data_rent %>%
  filter(jahr == 2010) %>%
  filter(mietekalt > 50, mietekalt < 10000) %>%
  ggplot(aes(x = mietekalt, y = after_stat(density))) +
  geom_histogram(binwidth = 20) +
  geom_vline(aes(xintercept = mean(mietekalt), color = "Mean"), linewidth = .8, linetype = "dashed") +
  geom_vline(aes(xintercept = median(mietekalt), color = "Median"), linewidth = .8, linetype = "dashed") +
  scale_color_manual("Statistics", values = c("Mean" = "red", "Median" = "blue"))+
  coord_cartesian(xlim = c(0, 2000)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = .1))+
  theme_bw() +
  theme(legend.position = c(0.8, 0.8), legend.title = element_blank(), legend.background = element_blank())+
  labs(x = "Kaltmiete 2010", y = "Dichte in %")

plot3 <- data_rent %>%
  filter(jahr == 2020) %>%
  filter(mietekalt > 50, mietekalt < 10000) %>%
  ggplot(aes(x = mietekalt, y = after_stat(density))) +
  geom_histogram(binwidth = 20) +
  geom_vline(aes(xintercept = mean(mietekalt), color = "Mean"), linewidth = .8, linetype = "dashed") +
  geom_vline(aes(xintercept = median(mietekalt), color = "Median"), linewidth = .8, linetype = "dashed") +
  scale_color_manual("Statistics", values = c("Mean" = "red", "Median" = "blue"))+
  coord_cartesian(xlim = c(0, 2000)) +
  scale_y_continuous(labels = scales::percent_format(accuracy = .1))+
  theme_bw() +
  theme(legend.position = c(0.8, 0.8), legend.title = element_blank(), legend.background = element_blank())+
  labs(x = "Kaltmiete 2020", y = "Dichte in %")

ggarrange(plot1,
          ggarrange(plot2, plot3, nrow = 2),
          nrow = 1)

ggsave("./plots/plot_miete.pdf")
```

Mittlere Kaltmiete auf Karte
```{r, fig.width=7.5, fig.height=2.5}
data_rent_sf <- data_rent %>%
  left_join(inspire_grid_berlin %>% select(r1_id, geom), by = "r1_id") %>%
  st_as_sf()

data_rent_sf_plot <- data_rent_sf %>%
  filter(jahr == 2015) %>%
  group_by(r1_id) %>%
  summarise(mietekalt = mean(mietekalt),
            wohnflaeche = mean(wohnflaeche),
            mietekalt_m2 = mean(mietekalt_m2))

plot1 <- data_rent_sf_plot %>%
  filter(mietekalt > quantile(mietekalt, probs = 0.01), mietekalt < quantile(mietekalt, probs = 0.99)) %>%
  ggplot()+
  geom_sf(aes(fill = mietekalt))+
  scale_fill_viridis_c(trans = "log10", breaks = c(400, 600, 900, 1300))+
  theme_bw()+
  theme(legend.position = "top",
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        plot.subtitle = element_text(hjust = .5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))+
  labs(fill = element_blank(),
       subtitle = "Kaltmiete (€)")

plot2 <- data_rent_sf_plot %>%
  filter(wohnflaeche > quantile(wohnflaeche, probs = 0.01), wohnflaeche < quantile(wohnflaeche, probs = 0.99)) %>%
  ggplot()+
  geom_sf(aes(fill = wohnflaeche))+
  scale_fill_viridis_c(trans = "log10", breaks = c(50, 70, 100, 130))+
  theme_bw()+
  theme(legend.position = "top",
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        plot.subtitle = element_text(hjust = .5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))+
  labs(fill = element_blank(),
       subtitle = "Wohnfläche (m²)")

plot3 <- data_rent_sf_plot %>%
  filter(mietekalt_m2 > quantile(mietekalt_m2, probs = 0.01), mietekalt_m2 < quantile(mietekalt_m2, probs = 0.99)) %>%
  ggplot()+
  geom_sf(aes(fill = mietekalt_m2))+
  scale_fill_viridis_c(trans = "log10", breaks = c(6, 8, 10, 12, 14))+
  theme_bw()+
  theme(legend.position = "top",
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        plot.subtitle = element_text(hjust = .5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))+
  labs(fill = element_blank(),
       subtitle = "Kaltmiete (€/m²)")

ggarrange(plot1, plot2, plot3, nrow = 1)

#rm(data_rent_sf_plot)

ggsave("./plots/plot_miete_karte_2015.pdf")
```


## Social Daten
Wie sehen ausgewählte Social-Variablen auf einer Karte aus?
```{r, fig.width=7.5, fig.height=2.5}
# arbeitslosenquote, kaufkraft_pro_haushalt, anteil_60_plus, anteil_auslaender

data_social_sf <- data_social %>%
  left_join(inspire_grid_berlin %>% select(r1_id, geom), by = "r1_id") %>%
  st_as_sf()
  
plot1 <- data_social_sf %>%
  filter(jahr == 2015) %>%
  ggplot(aes(fill = arbeitslosenquote, geometry = geom), linewidth = .1)+
  geom_sf()+
  scale_fill_viridis_c()+
  labs(subtitle = "Arbeitslosenquote",
       fill = element_blank())+
  theme_bw()+
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle=element_text(hjust=0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

plot2 <- data_social_sf %>%
  filter(jahr == 2015) %>%
  ggplot(aes(fill = kaufkraft_pro_haushalt, geometry = geom), linewidth = .1)+
  geom_sf()+
  scale_fill_viridis_c(trans = "log10", breaks = c(30000, 50000, 70000))+
  labs(subtitle = "Kaufkraft",
       fill = element_blank())+
  theme_bw()+
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle=element_text(hjust=0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

plot3 <- data_social_sf %>%
  filter(jahr == 2015) %>%
  filter(anteil_60_plus < 80) %>%
  ggplot(aes(fill = anteil_60_plus, geometry = geom), linewidth = .1)+
  geom_sf()+
  scale_fill_viridis_c()+
  labs(subtitle = "Anteil 60+",
       fill = element_blank())+
  theme_bw()+
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle=element_text(hjust=0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

plot4 <- data_social_sf %>%
  filter(jahr == 2015) %>%
  ggplot(aes(fill = anteil_auslaender, geometry = geom), linewidth = .1)+
  geom_sf()+
  scale_fill_viridis_c()+
  labs(subtitle = "Ausländeranteil",
       fill = element_blank())+
  theme_bw()+
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle=element_text(hjust=0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

ggarrange(plot1, plot2, plot3, plot4, nrow = 1)

ggsave("./plots/plot_data_social_2015.pdf")
```


# Clustering
k-means clustering mit den Variablen

- arbeitslosenquote
- kaufkraft_pro_haushalt
- anteil_auslaender
- anteil_efh
- anteil_60_plus

EDIT PASCAL:
es wäre gut Familien hier noch einfließen zu lassen, deshalb müssten wir zusätzliche Variable aus social Datensatz einbinden, 
Dies wird auch bei der Betrachtung der Mietbelastungsquoten verschiedener Haushalte wichtig, da wollten wir ja auch überprüfen ob Familien überdurchschnittliche Mietbelastungen haben

In datensatz müssten noch Variablen:
-r1_mso_p_singles
-r1_mso_p_familien

eingebunden werden

Es werden 4 Cluster verwendet. *Hier Begründung einfügen*

```{r}
data_clustering <- data_social %>%
  filter(jahr == 2015) %>%
  drop_na() %>%
  select(anzahl_haushalte, arbeitslosenquote, kaufkraft_pro_haushalt, anteil_auslaender, anteil_efh, anteil_60_plus) %>%
  as.matrix() %>%
  scale()

set.seed(1)
kmeans_result_2010 <- kmeans(data_clustering, centers = 4)

data_social %>%
  filter(jahr == 2015) %>%
  drop_na() %>%
  cbind(cluster = kmeans_result_2010$cluster) %>%
  mutate(cluster = as_factor(cluster)) %>%
  left_join(inspire_grid_berlin %>% select(r1_id), by = "r1_id") %>%
  st_as_sf() %>%
  ggplot()+
  geom_sf(aes(fill = cluster))+
  theme_bw()
```

Cluster sind sehr ähnlich zu den Wahlergebnissen der Bundestagswahl in Berlin 2016 ![Wahlergebnissen Berlin 2016](https://img.welt.de/img/politik/deutschland/mobile158256707/6751622257-ci23x11-w2000/DWO-IP-WahlergebnisBerlin-js-eps.jpg)

Wer steckt hinter den Clustern? Um diese Frage zu beantworten können wir die Mittelwerte der jeweiligen Cluster betrachten.
```{r}
kmeans_result_2010$centers %>% t() %>% round(2)
```

Die Werte können nicht direkt interpretiert werden, da sie vorher durch `scale()` mittelwertbereinigt und varianzbereinigt wurden. Was aber interpretiert werden kann ist der Unterschied zwischen den Werten.

Betrachten wir beispielsweise Cluster 3:

- Die Anzahl der Haushalte ist am geringsten, das heißt pro Quadratkilometer wohnen hier weniger Menschen als in den anderen Teilen Berlins.
- Die Arbeitslosenquote ist ebenfalls am kleinsten.
- Die Kaufkraft pro Haushalt ist dagegen im Vergleich am größten, es handelt sich also um eine wohlhabende Gegend.
- Der Anteil an Ausländern ist vergleichsweise klein, jedoch größer als in Cluster 1.
- Die Anzahl der Einfamilienhäuser ist im Vergleich groß, aber kleiner als in Cluster 1.
- Der Anteil der Bevölkerung über 60 Jahre ist ebenso mit Abstand am größten.

Anhand dieser Werte bzw. dem Vergleich zwischen den Werten haben wir eine zusammenfassende Beschreibung für die 4 Gebiete erstellt:

- Cluster 1: Stabile Wohngebiete
- Cluster 2: Sozial herausgeforderte Viertel
- Cluster 3: Wohlhabende Seniorengemeinschaften
- Cluster 4: Multikulturelle Ballungsräume

## Zeitliche Stabilität der Cluster
Sind die Cluster über die Zeit stabil? Das ist wichtig falls wir Regressionen basierend auf diesen Clusterungen vornehmen.
```{r}
# Split data by year
data_clustering_year <- data_social %>%
  select(jahr, anzahl_haushalte, arbeitslosenquote, kaufkraft_pro_haushalt, anteil_auslaender, anteil_efh, anteil_60_plus) %>%
  drop_na() %>%
  group_by(jahr) %>%
  filter(jahr %in% c(2005, 2010, 2015, 2019)) %>%
  group_split(.keep = FALSE)

kmeans_result_2005 <- data_clustering_year[[1]] %>% as.matrix() %>% scale() %>%
  kmeans(., centers = 4)
#kmeans_result_2005

kmeans_result_2010 <- data_clustering_year[[2]] %>% as.matrix() %>% scale() %>%
  kmeans(., centers = 4)
#kmeans_result_2010

kmeans_result_2015 <- data_clustering_year[[3]] %>% as.matrix() %>% scale() %>%
  kmeans(., centers = 4)
#kmeans_result_2015

kmeans_result_2019 <- data_clustering_year[[4]] %>% as.matrix() %>% scale() %>%
  kmeans(., centers = 4)
#kmeans_result_2019
```

```{r, fig.width=7.5, fig.height=2.5}
plot1 <- data_social_sf %>%
  filter(jahr == 2005) %>%
  select(r1_id, jahr, anzahl_haushalte, arbeitslosenquote, kaufkraft_pro_haushalt, anteil_auslaender, anteil_efh, anteil_60_plus) %>%
  drop_na() %>%
  cbind(cluster = kmeans_result_2005$cluster) %>%
  mutate(cluster = as_factor(cluster)) %>%
  ggplot()+
  geom_sf(aes(fill = cluster), linewidth = .1)+
  labs(subtitle = "Cluster in 2005")+
  theme_bw()+
  theme(legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle = element_text(hjust = .5))

plot2 <- data_social_sf %>%
  filter(jahr == 2010) %>%
  select(r1_id, jahr, anzahl_haushalte, arbeitslosenquote, kaufkraft_pro_haushalt, anteil_auslaender, anteil_efh, anteil_60_plus) %>%
  drop_na() %>%
  cbind(cluster = kmeans_result_2010$cluster) %>%
  mutate(cluster = as_factor(cluster)) %>%
  ggplot()+
  geom_sf(aes(fill = cluster), linewidth = .1)+
  labs(subtitle = "Cluster in 2010")+
  theme_bw()+
  theme(legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle = element_text(hjust = .5))

plot3 <- data_social_sf %>%
  filter(jahr == 2015) %>%
  select(r1_id, jahr, anzahl_haushalte, arbeitslosenquote, kaufkraft_pro_haushalt, anteil_auslaender, anteil_efh, anteil_60_plus) %>%
  drop_na() %>%
  cbind(cluster = kmeans_result_2015$cluster) %>%
  mutate(cluster = as_factor(cluster)) %>%
  ggplot()+
  geom_sf(aes(fill = cluster), linewidth = .1)+
  labs(subtitle = "Cluster in 2015")+
  theme_bw()+
  theme(legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle = element_text(hjust = .5))

plot4 <- data_social_sf %>%
  filter(jahr == 2019) %>%
  select(r1_id, jahr, anzahl_haushalte, arbeitslosenquote, kaufkraft_pro_haushalt, anteil_auslaender, anteil_efh, anteil_60_plus) %>%
  drop_na() %>%
  cbind(cluster = kmeans_result_2019$cluster) %>%
  mutate(cluster = as_factor(cluster)) %>%
  ggplot()+
  geom_sf(aes(fill = cluster), linewidth = .1)+
  labs(subtitle = "Cluster in 2019")+
  theme_bw()+
  theme(legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle = element_text(hjust = .5))

ggarrange(plot1, plot2, plot3, plot4, nrow = 2)


ggsave("./plots/plot_cluster_jahr_vergleich.pdf")
```

**TODO:** Clusterfarben konsistent machen

**Ergebnis:** Die Cluster sind über die Zeit ziemlich stabil. Erst in 2019 lassen sich einige größere Unterschiede bzw. Abweichungen erkennen. Wichtig ist, dass die Farbe der Cluster zwischen den Jahren nicht konstant ist. Es sollte also die Form der Cluster über die Jahre betrachtet werden. Statt 2020 wurde 2019 verwendet, da dies das letzte Jahr aus dem Datensatz ist.

# Regressionen

## Miete über die Jahre
Wie hat sich die Miete im Laufe der Jahre geändert?

Um diese Frage zu beantworten schätzen wir das folgende Regressionsmodell: $\ln(\text{Kaltmiete pro Quadratmeter}_i) = \beta_0 + \beta_1 \cdot \text{jahr}_i + \epsilon_i$. Wir benutzen den Logarithmus, um um näher an eine Normalverteilung der Residuen (siehe unten) heranzukommen. Nur das erlaubt die Anwendung eines t-Tests zur Bestimmung der statistischen Signifikanz.
```{r}
lm_miete_jahr <- data_rent %>%
  mutate(mietekalt_m2 = mietekalt / wohnflaeche) %>%
  filter(!is.na(mietekalt_m2)) %>%
  filter(mietekalt_m2 < quantile(mietekalt_m2, 0.99), mietekalt_m2 > quantile(mietekalt_m2, 0.01)) %>%
  lm(log(mietekalt_m2) ~ jahr, data = .)

summary(lm_miete_jahr)
```

Das Ergebnis der Regression spiegelt das wieder, was bereits im Boxplot oben gezeigt wurde: Die Miete steigt im Durchschnitt pro Jahr. Konkret wissen wir nun, dass die Miete pro Jahr im Schnitt um $\exp(0.06015)-1=6.1\%$ steigt. Der Wert des $\beta_0$ (Intercept) lässt sich nicht sinnvoll interpretieren, dieser würde die Miete im Jahr 0 angeben. Interessant ist für uns noch der Wert der t-Statistik beziehungsweise der p-Wert. Dieser ist nahe 0 und zeigt somit starke statistische Signifikanz. Dies impliziert, dass die Wahrscheinlichkeit, dass der ermittelte Zusammenhang lediglich auf Zufall beruht, äußerst gering ist. Das ist durch die schiere Größe des Datensatzes (knapp 1.9 Mio. Beobachtungen) jedoch nicht weiter überraschend. Umso wichtiger ist es hingegen, auch auf die ökonomische Relevanz des Zusammenhangs zu achten. Eine Steigerung von knapp 6% pro Jahr ist jedoch auch ökonomisch relevant, liegt diese doch weit über dem zu dieser Zeit vorherrschenden allgemeinen Inflationsniveau von unter 2%.

Zunächst wollen wir noch die Robustheit der Regression überprüfen um Sicher zu gehen, dass der t-Test überhaupt ein sinnvolles Ergebnis liefert. Dafür betrachten wir zuerst die Verteilung der Residuen, hier der Einfachheit als Dichte dargestellt.
```{r}
plot1 <- lm_miete_jahr$residuals %>%
  data.frame(resids = .) %>%
  ggplot(aes(x = resids))+
  geom_density()+
  coord_cartesian(xlim = c(-1, 1))+
  theme_bw()+
  labs(x = "Residuen", y = "Dichte")

plot2 <- lm_miete_jahr$residuals %>%
  data.frame(resids = .) %>%
  slice_sample(prop = .1) %>%
  ggplot(aes(sample = resids)) +
  stat_qq(alpha = .1, size = .2) +
  stat_qq_line() +
  xlab("Theoretische Quantile") +
  ylab("Stichproben-Quantile")+
  theme_bw()
  
ggarrange(plot1, plot2, nrow = 1)

ggsave("./plots/plot_regression_miete_jahr.pdf")
```


Im Ergebnis sehen wir eine ziemlich gute Normalverteilung. Links ist die Dichtefunktion der Residuen zu sehen und rechts ein QQ-Plot. Würden alle Punkte des QQ-Plots auf der Geraden liegen, so läge eine perfekte Normalverteilung in der Stichprobe vor. Dies ist hier nicht der Fall, da an den Rändern, insbesondere am rechten Rand, die Stichproben-Quantile über der Geraden liegen. Dies deutet auf eine (leicht) rechtsschiefe Verteilung hin.

```{r}
data_rent %>%
  mutate(mietekalt_m2 = mietekalt / wohnflaeche) %>%
  filter(!is.na(mietekalt_m2)) %>%
  filter(mietekalt_m2 < quantile(mietekalt_m2, 0.99), mietekalt_m2 > quantile(mietekalt_m2, 0.01)) %>%
  mutate(mietekalt_m2 = log(mietekalt_m2)) %>%
  group_by(jahr) %>%
  summarise(variance = var(mietekalt_m2)) %>%
  round(2)
```

Ein Problem ist jedoch Heteroskedastizität. So nennt man das Phänomen von nicht stabilen Varianzen. Für diesen Fall konkret sehen wir, dass die Varianz über die Jahre steigt, die Preise für Wohnungen streuen also immer weiter. Mathematisch bringt das Probleme mit der Robustheit der Schätzung, insbesondere kann dies zu Verzerrungne in den Standartfehlern führen. Diese werden wiederum für den t-Test und die Bestimmung der statistischen Signifikanz benötigt.

Um dieses Problem zu umgehen, berechnen wir im folgenden robuste Standartfehler und Vergleichen die Ergebnisse mit der ursprünglichen Regression. Dafür wird eine "heteroskedasticity-consistent" (HC) Kovarianzmatrix geschätzt.

```{r}
coeftest(lm_miete_jahr, vcov = vcovHC(lm_miete_jahr, type = "HC3"))
```

Wenn wir das Ergebnis dieser Schätzung mit dem des ursprünglichen Modells vergleichen, sehen wir keine Unterschiede bei den Schätzwerten der Betas. Die Standartfehler hingegen sind etwas größer. Das war zu erwarten, da durch die vorliegende Heteroskedastizität die Standartfehler in der ursprünglichen Regression verzerrt waren. Allerdings ist die Abweichung marginal, was sich auch in einem quasi unverändert bei fast Null liegendem p-Wert zeigt. Aufgrund dieser kleinen Abweichung, werden wir in den restlichen Auswertungen keine gesonderten Tests mehr aufgrund von Heteroskedastizität durchführen, wenn der p-Wert wie in diesem Fall extrehm nah an Null liegt. Denn selbst wenn die t-Statistiken leicht verzerrt sind, ändert das nichts an der Interpretation.

## Miete in "Brennpunkten" und Clustern

Hat sich die Miete in Brennpunkten über die Jahre stärker erhöht?

Hierzu müssen wir neben `data_rent` auch `data_social` verwenden. Wir definieren einen "Brennpunkt" als eine Gegend, in der die Arbeitslosenquote 2015 über 10% liegt und wo die Kaufkraft im unteren 20% Quantil liegt.

Als Regressionsmodell verwenden wir **TODO…** mit einem Interaktionsterm zwischen dem Jahr und der binären Ist-Brennpunkt Variable.

**TODO:** Erklären, wieso wir $jahr = jahr - 2007$ rechnen (um den Effekt von ist_brennpunkt und dem Intercept interpretieren zu können…)

```{r}
lm_miete_brennpunkt <- data_social %>%
  filter(jahr == 2015) %>%
  filter(!is.na(arbeitslosenquote), !is.na(kaufkraft_pro_haushalt)) %>%
  mutate(ist_brennpunkt = ifelse(arbeitslosenquote > 10 & kaufkraft_pro_haushalt < quantile(kaufkraft_pro_haushalt, .2), TRUE, FALSE)) %>%
  select(r1_id, ist_brennpunkt) %>%
  right_join(data_rent, by = "r1_id") %>%
  filter(!is.na(ist_brennpunkt)) %>%
  mutate(mietekalt_m2 = mietekalt / wohnflaeche) %>%
  filter(!is.na(mietekalt_m2)) %>%
  filter(mietekalt_m2 < quantile(mietekalt_m2, 0.99), mietekalt_m2 > quantile(mietekalt_m2, 0.01)) %>%
  mutate(jahr = jahr - 2007) %>%
  lm(log(mietekalt_m2) ~ jahr + ist_brennpunkt + ist_brennpunkt:jahr, data = .)

summary(lm_miete_brennpunkt)
```

**TODO** Interpretieren

Wir sollten noch die Güte der Regression überprüfen, indem wir die Residuen betrachten.
```{r}
plot1 <- lm_miete_brennpunkt$residuals %>%
  data.frame(resids = .) %>%
  ggplot(aes(x = resids))+
  geom_density()+
  coord_cartesian(xlim = c(-1, 1))+
  theme_bw()+
  labs(x = "Residuen", y = "Dichte")

plot2 <- lm_miete_brennpunkt$residuals %>%
  data.frame(resids = .) %>%
  slice_sample(prop = .1) %>%
  ggplot(aes(sample = resids)) +
  stat_qq(alpha = .1, size = .2) +
  stat_qq_line() +
  xlab("Theoretische Quantile") +
  ylab("Stichproben-Quantile")+
  theme_bw()
  
ggarrange(plot1, plot2, nrow = 1)

ggsave("./plots/plot_regression_brennpunkte.pdf")
```

Jetzt Regression mit den verschiedenen Clustern
```{r}
r1_id_cluster <- data_social %>%
  filter(jahr == 2015) %>%
  select(r1_id, jahr, anzahl_haushalte, arbeitslosenquote, kaufkraft_pro_haushalt, anteil_auslaender, anteil_efh, anteil_60_plus) %>%
  drop_na() %>%
  select(r1_id) %>%
  cbind(cluster = kmeans_result_2015$cluster) %>%
  mutate(cluster = as_factor(cluster))

lm_miete_cluster <- data_social %>%
  left_join(r1_id_cluster, by = "r1_id") %>%
  filter(!is.na(cluster)) %>%
  right_join(data_rent, by = c("r1_id", "jahr")) %>%
  filter(mietekalt_m2 > quantile(mietekalt_m2, probs = .01), mietekalt_m2 < quantile(mietekalt_m2, probs = .99)) %>%
  lm(log(mietekalt_m2) ~ jahr + cluster + cluster:jahr, data = .)

summary(lm_miete_cluster)
```

**ACHTUNG:** Wir müssen je das oberste und unterste 1% der Beobachtungen rauswerfen, da diese zu einer Verletzung der Normalverteilungsannahme führen. Das führt zu leicht unterschiedlichen Werten für die Betas.

Zur Erinnerung, die Cluster haben wir wie folgt beschrieben:

- Cluster 1: Stabile Wohngebiete
- Cluster 2: Sozial herausgeforderte Viertel
- Cluster 3: Wohlhabende Seniorengemeinschaften
- Cluster 4: Multikulturelle Ballungsräume

Insgesamt zeigt sich ein R^2 von 0.38. Das ist, gemessen an unserem "kleinen" Modell, schon beachtlich.

Wir sollten noch die Güte der Regression überprüfen, indem wir die Residuen betrachten.
```{r}
plot1 <- lm_miete_cluster$residuals %>%
  data.frame(resids = .) %>%
  ggplot(aes(x = resids))+
  geom_density()+
  coord_cartesian(xlim = c(-1, 1))+
  theme_bw()+
  labs(x = "Residuen", y = "Dichte")

plot2 <- lm_miete_cluster$residuals %>%
  data.frame(resids = .) %>%
  slice_sample(prop = .1) %>%
  ggplot(aes(sample = resids)) +
  stat_qq(alpha = .1, size = .2) +
  stat_qq_line() +
  xlab("Theoretische Quantile") +
  ylab("Stichproben-Quantile")+
  theme_bw()
  
ggarrange(plot1, plot2, nrow = 1)

ggsave("./plots/plot_regression_cluster.pdf")
```

Jetzt (nach der Ausreißerbereinigung) ist die Normalverteilungsannahme ziemlich gut erfüllt und wir können den Ergebnissen der Tests (besser) vertrauen.

## Mietbelastung (Miete / Einkommen)

Erstmal einen Boxplot
```{r}
data_social %>%
  left_join(r1_id_cluster, by = "r1_id") %>%
  right_join(data_rent, by = c("r1_id", "jahr")) %>%
  filter(mietekalt_m2 > quantile(mietekalt_m2, probs = .01), mietekalt_m2 < quantile(mietekalt_m2, probs = .99)) %>%
  mutate(mietbelastung = mietekalt*12 / kaufkraft_pro_haushalt) %>%
  filter(!is.na(cluster)) %>%
  filter(jahr == 2015) %>%
  slice_sample(n = 100000) %>%
  ggplot(aes(x = cluster, y = mietbelastung, group = cluster))+
  #geom_boxplot(outlier.shape = NA)+
  geom_violin()+
  stat_summary(fun = "mean",
               geom = "crossbar", 
               width = 0.5,
               aes(colour = "Mean"))+
  stat_summary(fun = "median",
               geom = "crossbar", 
               width = 0.5,
               aes(colour = "Median"))+
  scale_color_manual("Statistics", values = c("Mean" = "red", "Median" = "blue"))+
  coord_cartesian(ylim = c(0, .5))+
  theme_bw()+
  theme(legend.position = "right")+
  labs(x = "Cluster",
       y = "Mietbelastung",
       color = element_blank())

ggsave("./plots/plot_mietbelastung_2015.pdf")
```


```{r}
lm_mietbelastung <- data_social %>%
  left_join(r1_id_cluster, by = "r1_id") %>%
  filter(!is.na(cluster)) %>%
  right_join(data_rent, by = c("r1_id", "jahr")) %>%
  filter(mietekalt_m2 > quantile(mietekalt_m2, probs = .01), mietekalt_m2 < quantile(mietekalt_m2, probs = .99)) %>%
  mutate(mietbelastung = mietekalt*12 / kaufkraft_pro_haushalt) %>%
  lm(mietbelastung ~ jahr + cluster + cluster:jahr, data = .)
summary(lm_mietbelastung)

lm_mietbelastung %>%
  broom::augment() %>%
  slice_sample(n = 1000, by = cluster) %>%
  ggplot(aes(x = jahr, y = mietbelastung, color = cluster))+
  geom_point(alpha = .05)+
  geom_line(aes(y = .fitted))+
  coord_cartesian(ylim = c(0, .4))+
  scale_x_continuous(breaks = c(2010, 2013, 2016, 2019)) +
  facet_wrap(~cluster)+
  theme_bw()+
  labs(x = "Jahr",
       y = "Mietbelastung")+
  theme(legend.position = "none")

ggsave("./plots/plot_regression_mietbelastung.pdf")
```


**TODO:** Rausfinden, warum die Jahre 2006 bis 2008 in data social fehlen

- Cluster 1: Stabile Wohngebiete
- Cluster 2: Sozial herausgeforderte Viertel
- Cluster 3: Wohlhabende Seniorengemeinschaften
- Cluster 4: Multikulturelle Ballungsräume

**TODO:** Interpretieren
**TODO:** Rausfinden, warum das R^2 hier so viel kleiner ist als bei den Regressionen oben (mit `log(mietekalt_m2) ~ jahr + cluster + cluster:jahr`)

# Analyse Teil 1: Konzentration der Bevölkerungsgruppen

Entwicklung der Kaufkraft zwischen 2010 und 2020

```{r}
 data_social %>%
  filter(jahr %in% 2010:2020) %>%
  filter(!is.na(kaufkraft_pro_haushalt)) %>%
  ggplot(aes(x = jahr, y = kaufkraft_pro_haushalt, group = jahr))+
  #geom_boxplot(outlier.shape = NA)+
  geom_violin()+
  coord_cartesian(ylim = c(20000, 60000))+
  scale_x_continuous(breaks = 2010:2020, labels = 10:20)+
  theme_bw()+
  labs(x = "Jahr", y = "Einkommen pro Haushalt")

ggsave("./plots/plot_entwicklung_kaufkraft.pdf")
```

Verteilung der Arbeitslosenquote im Jahr 2010 und 2019

```{r}
data_social_sf <- data_social %>%
  left_join(inspire_grid_berlin %>% select(r1_id, geom), by = "r1_id") %>%
  st_as_sf()
  
plot1 <- data_social_sf %>%
  filter(jahr == 2010) %>%
  ggplot(aes(fill = arbeitslosenquote, geometry = geom), linewidth = .1)+
  geom_sf()+
  scale_fill_viridis_c(breaks = c(5, 10, 15, 20))+
  labs(subtitle = "Arbeitslosenquote in %",
       fill = element_blank())+
  theme_bw()+
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle=element_text(hjust=0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

plot2 <- data_social_sf %>%
  filter(jahr == 2019) %>%
  ggplot(aes(fill = arbeitslosenquote, geometry = geom), linewidth = .1)+
  geom_sf()+
  scale_fill_viridis_c(breaks = c(5, 10, 15, 20))+
  labs(subtitle = "Arbeitslosenquote in %",
       fill = element_blank())+
  theme_bw()+
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle=element_text(hjust=0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))


Verteilung der Kaufkraft im Jahr 2010 und 2019

```{r}
data_social_sf <- data_social %>%
  left_join(inspire_grid_berlin %>% select(r1_id, geom), by = "r1_id") %>%
  st_as_sf()

mittelwert_kaufkraft <- data_social %>%
  filter(jahr == 2010) %>%
  summarise(mittelwert_kaufkraft = median(kaufkraft_pro_haushalt, na.rm = TRUE))
  
plot7 <- data_social_sf %>%
  filter(jahr == 2010) %>%
  ggplot(aes(fill = cut(kaufkraft_pro_haushalt, 
                      breaks = c(0, 20000, 30000, 50000, Inf), 
                      labels = c("< 20000", "20000 - 30000", "30000 - 50000", "> 50000"), 
                      drop = TRUE), 
       geometry = geom), linewidth = .1) +
  geom_sf() +
  scale_fill_manual(values = c("red", "orange", "white", "green")) +
  labs(subtitle = "Kaufkraft pro Haushalt in € in 2010", fill = NULL) +
  theme_bw() +
  theme(
    legend.position = "top",
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    plot.subtitle = element_text(hjust = 0.5),
    legend.margin = margin(t = 0, b = -5, l = 0, r = 0)
)

plot8 <- data_social_sf %>%
  filter(jahr == 2019) %>%
  ggplot(aes(fill = cut(kaufkraft_pro_haushalt, 
                      breaks = c(0, 25000, 35000, 50000, Inf), 
                      labels = c("< 25000", "25000 - 35000", "35000 - 50000", "> 50000"), 
                      drop = TRUE), 
       geometry = geom), linewidth = .1) +
  geom_sf() +
  scale_fill_manual(values = c("red", "orange", "white", "green")) +
  labs(subtitle = "Kaufkraft pro Haushalt in € in 2019", fill = NULL) +
  theme_bw() +
  theme(
    legend.position = "top",
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    plot.subtitle = element_text(hjust = 0.5),
    legend.margin = margin(t = 0, b = -5, l = 0, r = 0)
  )


plot_grid(plot7, plot8, labels = c('A', 'B')

install.packages("cowplot")
install.packages("ggplot2")

library(ggplot2)
library(cowplot)
```

Verteilung nach Ausländeranteil im Jahr 2010 und 2019

```{r}
plot1 <- data_social_sf %>%
  filter(jahr == 2010) %>%
  ggplot(aes(fill = anteil_auslaender, geometry = geom), linewidth = .1)+
  geom_sf()+
  scale_fill_viridis_c()+
  labs(subtitle = "Ausländeranteil in %",
       fill = element_blank())+
  theme_bw()+
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle=element_text(hjust=0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

plot2 <- data_social_sf %>%
  filter(jahr == 2019) %>%
  ggplot(aes(fill = anteil_auslaender, geometry = geom), linewidth = .1)+
  geom_sf()+
  scale_fill_viridis_c()+
  labs(subtitle = "Ausländeranteil in %",
       fill = element_blank())+
  theme_bw()+
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle=element_text(hjust=0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))
```

Verteilung nach LQ

```{r}
data_LQ_sf <- data_social_sf %>%
  select(r1_id, jahr, arbeitslosenquote, anteil_auslaender, anzahl_haushalte, kaufkraft_pro_haushalt) %>%
  group_by(jahr) %>%
  filter(!is.na(anzahl_haushalte)) %>%
  mutate(LQ_arbeitslose = arbeitslosenquote / weighted.mean(arbeitslosenquote, anzahl_haushalte, na.rm = TRUE),
         LQ_auslaender = anteil_auslaender  / weighted.mean(anteil_auslaender, anzahl_haushalte, na.rm = TRUE),
         .keep = c("unused")) %>%
  ungroup()

#LQ Arbeitslosenquote 2010

plot1 <- data_LQ_sf %>%
  filter(jahr == 2010) %>%
  ggplot(aes(fill = cut(LQ_arbeitslose, 
                      breaks = c(0, 0.3, 0.7, 1.2, 1.7, Inf), 
                      labels = c("<= 0.3", "0.3 - 0.7", "0.7 - 1.2", "1.2 - 1.7", ">= 1.7")), 
       geometry = geom), linewidth = .1) +
  geom_sf() +
  scale_fill_manual(values = c("blue", "green", "white", "orange", "red")) +
  labs(subtitle = "LQ Arbeitslose 2010", fill = NULL) +
  theme_bw() +
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle = element_text(hjust = 0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

#LQ Arbeitslosenquote 2019

plot2 <- data_LQ_sf %>%
  filter(jahr == 2019) %>%
  ggplot(aes(fill = cut(LQ_arbeitslose, 
                      breaks = c(0, 0.3, 0.7, 1.2, 1.7, Inf), 
                      labels = c("<= 0.3", "0.3 - 0.7", "0.7 - 1.2", "1.2 - 1.7", ">= 1.7"), drop = TRUE), 
       geometry = geom), linewidth = .1) +
  geom_sf() +
  scale_fill_manual(values = c("blue", "green", "white", "orange", "red")) +
  labs(subtitle = "LQ Arbeitslose 2019", fill = NULL) +
  theme_bw() +
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle = element_text(hjust = 0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

plot_grid(plot1, plot2, labels = c('A', 'B'))

#LQ Ausländeranteil 2010

plot5 <- data_LQ_sf %>%
  filter(jahr == 2010) %>%
  ggplot(aes(fill = cut(LQ_auslaender, 
                      breaks = c(0, 0.3, 0.7, 1.2, 1.7, Inf), 
                      labels = c("<= 0.3", "0.3 - 0.7", "0.7 - 1.2", "1.2 - 1.7", ">= 1.7"), drop = TRUE), 
       geometry = geom), linewidth = .1) +
  geom_sf() +
  scale_fill_manual(values = c("blue", "green", "white", "orange", "red")) +
  labs(subtitle = "LQ Ausländer 2010", fill = NULL) +
  theme_bw() +
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle = element_text(hjust = 0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

#LQ Ausländeranteil 2019

plot6 <- data_LQ_sf %>%
  filter(jahr == 2019) %>%
  ggplot(aes(fill = cut(LQ_auslaender, 
                      breaks = c(0, 0.3, 0.7, 1.2, 1.7, Inf), 
                      labels = c("<= 0.3", "0.3 - 0.7", "0.7 - 1.2", "1.2 - 1.7", ">= 1.7"), drop = TRUE), 
       geometry = geom), linewidth = .1) +
  geom_sf() +
  scale_fill_manual(values = c("blue", "green", "white", "orange", "red")) +
  labs(subtitle = "LQ Ausländer 2019", fill = NULL) +
  theme_bw() +
  theme(legend.position = "top",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        plot.subtitle = element_text(hjust = 0.5),
        legend.margin = margin(t = 0, b = -5, l = 0, r = 0))

plot_grid(plot5, plot6, labels = c('A', 'B'))
```

